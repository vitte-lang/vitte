

# /Users/vincent/Documents/Github/vitte/std/runtime/src/intrinsics.vitte
# -----------------------------------------------------------------------------
# std/runtime/intrinsics
# -----------------------------------------------------------------------------
# MAX intrinsic fa√ßade for codegen + stdlib.
#
# Goals:
# - Centralize all low-level primitives that must be provided by the runtime
#   backend (C/VM).
# - Keep signatures simple and ABI-stable.
# - Provide thin wrappers where needed (validation, asserts).
# - Avoid heavy dependencies; only std.runtime.assert + std.string as needed.
#
# Categories:
# - Panic / formatting (minimal)
# - Memory: memcpy/memmove/memset/memcmp/memswap/memzero_secure
# - Allocation: malloc/free/realloc (optional)
# - Pointer loads/stores: u8/u16/u32/u64 (LE) aligned+unaligned
# - Byte IO: read/write bytes (for ptr facade)
# - Time hooks (optional): monotonic/system sleep
# - RNG hooks (optional)
#
# Blocks use `.end` only.
# -----------------------------------------------------------------------------

module std.runtime.intrinsics

use std.runtime
use std.runtime.assert
use std.string

type Bool = bool
type U8   = u8
type U16  = u16
type U32  = u32
type U64  = u64
type I32  = i32
type I64  = i64
type Str  = str

# We expose Ptr as U64 to keep ABI stable.
# If your compiler has ptr<T>, keep Ptr aliased to the raw address.

type Ptr = U64

# -----------------------------------------------------------------------------
# Panic + minimal formatting helpers
# -----------------------------------------------------------------------------

# Panic terminates execution. Implemented by backend.
fn panic(msg: Str) -> never
  do std.runtime::panic(msg)
.end

# Concatenation helpers for panic messages.
# Backends may implement efficient concatenation / small buffer formatting.
fn panic_concat2(a: Str, b: Str) -> Str
  ret std.runtime::panic_concat2(a, b)
.end

fn panic_concat3(a: Str, b: Str, c: Str) -> Str
  ret std.runtime::panic_concat3(a, b, c)
.end

# Minimal formatting for assert helpers (backend-provided).
fn fmt_u64_eq(a: U64, b: U64) -> Str
  ret std.runtime::fmt_u64_eq(a, b)
.end

fn fmt_u64_ne(a: U64, b: U64) -> Str
  ret std.runtime::fmt_u64_ne(a, b)
.end

fn fmt_i64_eq(a: I64, b: I64) -> Str
  ret std.runtime::fmt_i64_eq(a, b)
.end

fn fmt_u32_eq(a: U32, b: U32) -> Str
  ret std.runtime::fmt_u32_eq(a, b)
.end

fn fmt_i32_eq(a: I32, b: I32) -> Str
  ret std.runtime::fmt_i32_eq(a, b)
.end

fn fmt_bool_eq(a: Bool, b: Bool) -> Str
  ret std.runtime::fmt_bool_eq(a, b)
.end

# -----------------------------------------------------------------------------
# Memory intrinsics
# -----------------------------------------------------------------------------

fn memcpy(dst: Ptr, src: Ptr, n: U64) -> Ptr
  do std.runtime.assert::assert(dst != 0 || n == 0, "memcpy: dst null")
  do std.runtime.assert::assert(src != 0 || n == 0, "memcpy: src null")
  ret std.runtime::memcpy(dst, src, n)
.end

fn memmove(dst: Ptr, src: Ptr, n: U64) -> Ptr
  do std.runtime.assert::assert(dst != 0 || n == 0, "memmove: dst null")
  do std.runtime.assert::assert(src != 0 || n == 0, "memmove: src null")
  ret std.runtime::memmove(dst, src, n)
.end

fn memset(dst: Ptr, byte: U32, n: U64) -> Ptr
  do std.runtime.assert::assert(dst != 0 || n == 0, "memset: dst null")
  ret std.runtime::memset(dst, byte, n)
.end

fn memcmp(a: Ptr, b: Ptr, n: U64) -> I32
  do std.runtime.assert::assert(a != 0 || n == 0, "memcmp: a null")
  do std.runtime.assert::assert(b != 0 || n == 0, "memcmp: b null")
  ret std.runtime::memcmp(a, b, n)
.end

fn memswap(a: Ptr, b: Ptr, n: U64)
  do std.runtime.assert::assert(a != 0 || n == 0, "memswap: a null")
  do std.runtime.assert::assert(b != 0 || n == 0, "memswap: b null")
  do std.runtime::memswap(a, b, n)
.end

# Must not be optimized away by backend.
fn memzero_secure(dst: Ptr, n: U64) -> Ptr
  do std.runtime.assert::assert(dst != 0 || n == 0, "memzero_secure: dst null")
  ret std.runtime::memzero_secure(dst, n)
.end

# -----------------------------------------------------------------------------
# Allocation intrinsics
# -----------------------------------------------------------------------------

fn malloc(size: U64, align: U64) -> Ptr
  do std.runtime.assert::assert(size != 0, "malloc: size=0")
  do std.runtime.assert::assert(align != 0, "malloc: align=0")
  ret std.runtime::malloc(size, align)
.end

fn free(ptr: Ptr, size: U64, align: U64)
  if ptr == 0
    ret
  .end
  do std.runtime::free(ptr, size, align)
.end

fn realloc(ptr: Ptr, old_size: U64, new_size: U64, align: U64) -> Ptr
  # Backend may implement realloc; if absent, fallback may allocate+copy+free.
  do std.runtime.assert::assert(align != 0, "realloc: align=0")
  ret std.runtime::realloc(ptr, old_size, new_size, align)
.end

# -----------------------------------------------------------------------------
# Pointer loads/stores (little-endian)
# -----------------------------------------------------------------------------

fn ptr_load_u8(p: Ptr) -> U32
  do std.runtime.assert::assert(p != 0, "ptr_load_u8: null")
  ret std.runtime::ptr_load_u8(p)
.end

fn ptr_store_u8(p: Ptr, v: U32)
  do std.runtime.assert::assert(p != 0, "ptr_store_u8: null")
  do std.runtime::ptr_store_u8(p, v)
.end

fn ptr_load_u16_le(p: Ptr) -> U32
  do std.runtime.assert::assert(p != 0, "ptr_load_u16_le: null")
  ret std.runtime::ptr_load_u16_le(p)
.end

fn ptr_load_u16_le_unaligned(p: Ptr) -> U32
  do std.runtime.assert::assert(p != 0, "ptr_load_u16_le_unaligned: null")
  ret std.runtime::ptr_load_u16_le_unaligned(p)
.end

fn ptr_store_u16_le(p: Ptr, v: U32)
  do std.runtime.assert::assert(p != 0, "ptr_store_u16_le: null")
  do std.runtime::ptr_store_u16_le(p, v)
.end

fn ptr_store_u16_le_unaligned(p: Ptr, v: U32)
  do std.runtime.assert::assert(p != 0, "ptr_store_u16_le_unaligned: null")
  do std.runtime::ptr_store_u16_le_unaligned(p, v)
.end

fn ptr_load_u32_le(p: Ptr) -> U32
  do std.runtime.assert::assert(p != 0, "ptr_load_u32_le: null")
  ret std.runtime::ptr_load_u32_le(p)
.end

fn ptr_load_u32_le_unaligned(p: Ptr) -> U32
  do std.runtime.assert::assert(p != 0, "ptr_load_u32_le_unaligned: null")
  ret std.runtime::ptr_load_u32_le_unaligned(p)
.end

fn ptr_store_u32_le(p: Ptr, v: U32)
  do std.runtime.assert::assert(p != 0, "ptr_store_u32_le: null")
  do std.runtime::ptr_store_u32_le(p, v)
.end

fn ptr_store_u32_le_unaligned(p: Ptr, v: U32)
  do std.runtime.assert::assert(p != 0, "ptr_store_u32_le_unaligned: null")
  do std.runtime::ptr_store_u32_le_unaligned(p, v)
.end

fn ptr_load_u64_le(p: Ptr) -> U64
  do std.runtime.assert::assert(p != 0, "ptr_load_u64_le: null")
  ret std.runtime::ptr_load_u64_le(p)
.end

fn ptr_load_u64_le_unaligned(p: Ptr) -> U64
  do std.runtime.assert::assert(p != 0, "ptr_load_u64_le_unaligned: null")
  ret std.runtime::ptr_load_u64_le_unaligned(p)
.end

fn ptr_store_u64_le(p: Ptr, v: U64)
  do std.runtime.assert::assert(p != 0, "ptr_store_u64_le: null")
  do std.runtime::ptr_store_u64_le(p, v)
.end

fn ptr_store_u64_le_unaligned(p: Ptr, v: U64)
  do std.runtime.assert::assert(p != 0, "ptr_store_u64_le_unaligned: null")
  do std.runtime::ptr_store_u64_le_unaligned(p, v)
.end

# -----------------------------------------------------------------------------
# Byte IO (for ptr facade)
# -----------------------------------------------------------------------------

fn ptr_read_bytes(p: Ptr, n: U64) -> Str
  do std.runtime.assert::assert(p != 0 || n == 0, "ptr_read_bytes: null")
  ret std.runtime::ptr_read_bytes(p, n)
.end

fn ptr_write_bytes(p: Ptr, s: Str)
  if std.string::len(s) == 0
    ret
  .end
  do std.runtime.assert::assert(p != 0, "ptr_write_bytes: null")
  do std.runtime::ptr_write_bytes(p, s)
.end

# -----------------------------------------------------------------------------
# Time hooks (optional)
# -----------------------------------------------------------------------------

fn time_monotonic_ns() -> U64
  ret std.runtime::time_monotonic_ns()
.end

fn time_system_ns() -> U64
  ret std.runtime::time_system_ns()
.end

fn sleep_ms(ms: U64)
  do std.runtime::sleep_ms(ms)
.end

# -----------------------------------------------------------------------------
# RNG hooks (optional)
# -----------------------------------------------------------------------------

fn rng_fill_bytes(dst: Ptr, n: U64) -> Bool
  do std.runtime.assert::assert(dst != 0 || n == 0, "rng_fill_bytes: dst null")
  ret std.runtime::rng_fill_bytes(dst, n)
.end

# -----------------------------------------------------------------------------
# Smoke tests (pure surface)
# -----------------------------------------------------------------------------

scn test_intrinsics_surface
  let _ = memcpy
  let _ = memmove
  let _ = memset
  let _ = memcmp
  let _ = memswap
  let _ = memzero_secure

  let _ = malloc
  let _ = free
  let _ = realloc

  let _ = ptr_load_u8
  let _ = ptr_store_u8
  let _ = ptr_load_u16_le
  let _ = ptr_load_u16_le_unaligned
  let _ = ptr_store_u16_le
  let _ = ptr_store_u16_le_unaligned
  let _ = ptr_load_u32_le
  let _ = ptr_load_u32_le_unaligned
  let _ = ptr_store_u32_le
  let _ = ptr_store_u32_le_unaligned
  let _ = ptr_load_u64_le
  let _ = ptr_load_u64_le_unaligned
  let _ = ptr_store_u64_le
  let _ = ptr_store_u64_le_unaligned

  let _ = time_monotonic_ns
  let _ = time_system_ns
  let _ = sleep_ms

  let _ = rng_fill_bytes
.end

# End of std.runtime.intrinsics
