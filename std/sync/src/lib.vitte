# -----------------------------------------------------------------------------
# std/sync
# -----------------------------------------------------------------------------
# Synchronization primitives (bootstrap-friendly).
#
# IMPORTANT:
# - Default backend is "local" (single-thread). Semantics are best-effort.
# - API surface is designed to be swapped for real thread/atomic primitives
#   later without rewriting call sites.
# - All operations are explicit (no RAII). Guards must be unlocked manually.
# - Return (ok, err, ...) tuples instead of throwing.
# - All blocks use `.end` only.
# -----------------------------------------------------------------------------

module std.sync

use std.collections
use std.runtime

# -----------------------------------------------------------------------------
# Types / errors
# -----------------------------------------------------------------------------

type Bool = bool

type U8    = u8
type U32   = u32
type U64   = u64
type I64   = i64
type USize = usize

type Ptr[T] = ptr[T]

type SyncError enum
  Ok
  Invalid
  OutOfMemory
  Unsupported
  Busy
  Timeout
  WouldBlock
  Unexpected
.end

fn sync_error_ok(e: SyncError) -> Bool
  ret e == SyncError::Ok
.end

fn sync_expect(ok: Bool, msg: str)
  do std.runtime::assert(ok, msg)
.end

# -----------------------------------------------------------------------------
# SpinLock (local)
# -----------------------------------------------------------------------------

type SpinLock struct
  locked: Bool
.end

fn spinlock_new() -> SpinLock
  let s: SpinLock
  set s.locked = false
  ret s
.end

fn spinlock_try_lock(s: &SpinLock) -> (Bool, SyncError)
  if s.locked
    ret (false, SyncError::Busy)
  .end
  set s.locked = true
  ret (true, SyncError::Ok)
.end

fn spinlock_lock_spin(s: &SpinLock, spins: U32) -> (Bool, SyncError)
  if !s.locked
    set s.locked = true
    ret (true, SyncError::Ok)
  .end

  if spins == 0
    ret (false, SyncError::Busy)
  .end

  let i: U32
  set i = 0
  while i < spins
    if !s.locked
      set s.locked = true
      ret (true, SyncError::Ok)
    .end
    set i = i + 1
  .end

  ret (false, SyncError::Busy)
.end

fn spinlock_unlock(s: &SpinLock) -> (Bool, SyncError)
  if !s.locked
    ret (false, SyncError::Invalid)
  .end
  set s.locked = false
  ret (true, SyncError::Ok)
.end

# -----------------------------------------------------------------------------
# Mutex (local)
# -----------------------------------------------------------------------------

# Local mutex state.
# - `locked` indicates whether the mutex is currently held.
# - `depth` supports re-entrant locking within the same thread (best-effort).
#   In a real multi-thread backend, this would be tied to a thread id.

type Mutex struct
  locked: Bool
  depth: U32
.end

fn mutex_new() -> Mutex
  let m: Mutex
  set m.locked = false
  set m.depth = 0
  ret m
.end

fn mutex_is_locked(m: &Mutex) -> Bool
  ret m.locked
.end

fn mutex_try_lock(m: &Mutex) -> (Bool, SyncError)
  if !m.locked
    set m.locked = true
    set m.depth = 1
    ret (true, SyncError::Ok)
  .end

  # best-effort re-entrant (single-thread semantics)
  set m.depth = m.depth + 1
  ret (true, SyncError::Ok)
.end

# Lock with a bounded spin.
# - If already locked by a different logical owner, a real backend would block.
# - Here, if locked and depth>0 => re-entrant.
fn mutex_lock_spin(m: &Mutex, spins: U32) -> (Bool, SyncError)
  if !m.locked
    set m.locked = true
    set m.depth = 1
    ret (true, SyncError::Ok)
  .end

  if m.depth > 0
    set m.depth = m.depth + 1
    ret (true, SyncError::Ok)
  .end

  if spins == 0
    ret (false, SyncError::Busy)
  .end

  let i: U32
  set i = 0
  while i < spins
    if !m.locked
      set m.locked = true
      set m.depth = 1
      ret (true, SyncError::Ok)
    .end
    set i = i + 1
  .end

  ret (false, SyncError::Busy)
.end

# Default lock is non-blocking (attempt only).
fn mutex_lock(m: &Mutex) -> (Bool, SyncError)
  ret mutex_lock_spin(m, 0)
.end

fn mutex_unlock(m: &Mutex) -> (Bool, SyncError)
  if !m.locked
    ret (false, SyncError::Invalid)
  .end

  if m.depth == 0
    ret (false, SyncError::Invalid)
  .end

  if m.depth > 1
    set m.depth = m.depth - 1
    ret (true, SyncError::Ok)
  .end

  set m.depth = 0
  set m.locked = false
  ret (true, SyncError::Ok)
.end

# Guard (explicit release required)

type MutexGuard struct
  m: Ptr[Mutex]
  held: Bool
.end

fn mutex_lock_guard(m: &Mutex) -> (Bool, SyncError, MutexGuard)
  let ok: Bool
  let e: SyncError
  (ok, e) = mutex_lock(m)

  let g: MutexGuard
  set g.m = (Ptr[Mutex])m
  set g.held = ok

  if !ok
    ret (false, e, g)
  .end

  ret (true, SyncError::Ok, g)
.end

fn mutex_try_lock_guard(m: &Mutex) -> (Bool, SyncError, MutexGuard)
  let ok: Bool
  let e: SyncError
  (ok, e) = mutex_try_lock(m)

  let g: MutexGuard
  set g.m = (Ptr[Mutex])m
  set g.held = ok

  if !ok
    ret (false, e, g)
  .end

  ret (true, SyncError::Ok, g)
.end

fn mutex_guard_unlock(g: &MutexGuard) -> (Bool, SyncError)
  if !g.held
    ret (false, SyncError::Invalid)
  .end
  set g.held = false
  ret mutex_unlock(g.m)
.end

# -----------------------------------------------------------------------------
# MutexCell[T] (local) - combines Mutex + value
# -----------------------------------------------------------------------------

# NOTE: In the local backend there is no real data-race protection.
# This is a convenience for call sites; a real backend can enforce safety.

type MutexCell[T] struct
  m: Mutex
  v: T
.end

fn mutexcell_new[T](v: T) -> MutexCell[T]
  let c: MutexCell[T]
  set c.m = mutex_new()
  set c.v = v
  ret c
.end

fn mutexcell_lock[T](c: &MutexCell[T]) -> (Bool, SyncError, MutexGuard)
  ret mutex_lock_guard(&c.m)
.end

fn mutexcell_try_lock[T](c: &MutexCell[T]) -> (Bool, SyncError, MutexGuard)
  ret mutex_try_lock_guard(&c.m)
.end

# Pointer to the inner value.
# Caller must hold the lock for safe use in a real backend.
fn mutexcell_ptr[T](c: &MutexCell[T]) -> Ptr[T]
  ret (Ptr[T])&c.v
.end

# -----------------------------------------------------------------------------
# RwLock (local)
# -----------------------------------------------------------------------------

type RwLock struct
  writer: Bool
  readers: U32
.end

fn rwlock_new() -> RwLock
  let r: RwLock
  set r.writer = false
  set r.readers = 0
  ret r
.end

fn rwlock_try_read(r: &RwLock) -> (Bool, SyncError)
  if r.writer
    ret (false, SyncError::Busy)
  .end
  set r.readers = r.readers + 1
  ret (true, SyncError::Ok)
.end

fn rwlock_try_write(r: &RwLock) -> (Bool, SyncError)
  if r.writer || r.readers != 0
    ret (false, SyncError::Busy)
  .end
  set r.writer = true
  ret (true, SyncError::Ok)
.end

# Default ops are non-blocking.
fn rwlock_read(r: &RwLock) -> (Bool, SyncError)
  ret rwlock_try_read(r)
.end

fn rwlock_write(r: &RwLock) -> (Bool, SyncError)
  ret rwlock_try_write(r)
.end

fn rwlock_read_unlock(r: &RwLock) -> (Bool, SyncError)
  if r.readers == 0
    ret (false, SyncError::Invalid)
  .end
  set r.readers = r.readers - 1
  ret (true, SyncError::Ok)
.end

fn rwlock_write_unlock(r: &RwLock) -> (Bool, SyncError)
  if !r.writer
    ret (false, SyncError::Invalid)
  .end
  set r.writer = false
  ret (true, SyncError::Ok)
.end

# Guards

type RwReadGuard struct
  r: Ptr[RwLock]
  held: Bool
.end

type RwWriteGuard struct
  r: Ptr[RwLock]
  held: Bool
.end

fn rwlock_read_guard(r: &RwLock) -> (Bool, SyncError, RwReadGuard)
  let ok: Bool
  let e: SyncError
  (ok, e) = rwlock_read(r)

  let g: RwReadGuard
  set g.r = (Ptr[RwLock])r
  set g.held = ok

  if !ok
    ret (false, e, g)
  .end
  ret (true, SyncError::Ok, g)
.end

fn rwlock_write_guard(r: &RwLock) -> (Bool, SyncError, RwWriteGuard)
  let ok: Bool
  let e: SyncError
  (ok, e) = rwlock_write(r)

  let g: RwWriteGuard
  set g.r = (Ptr[RwLock])r
  set g.held = ok

  if !ok
    ret (false, e, g)
  .end
  ret (true, SyncError::Ok, g)
.end

fn rwread_guard_unlock(g: &RwReadGuard) -> (Bool, SyncError)
  if !g.held
    ret (false, SyncError::Invalid)
  .end
  set g.held = false
  ret rwlock_read_unlock(g.r)
.end

fn rwwrite_guard_unlock(g: &RwWriteGuard) -> (Bool, SyncError)
  if !g.held
    ret (false, SyncError::Invalid)
  .end
  set g.held = false
  ret rwlock_write_unlock(g.r)
.end

# -----------------------------------------------------------------------------
# Once (local)
# -----------------------------------------------------------------------------

# Two-phase protocol:
#   (ok, e, run) = once_begin(&o)
#   if run: init; once_complete(&o)

type Once struct
  done: Bool
  running: Bool
.end

fn once_new() -> Once
  let o: Once
  set o.done = false
  set o.running = false
  ret o
.end

fn once_begin(o: &Once) -> (Bool, SyncError, Bool)
  if o.done
    ret (true, SyncError::Ok, false)
  .end
  if o.running
    ret (false, SyncError::WouldBlock, false)
  .end
  set o.running = true
  ret (true, SyncError::Ok, true)
.end

fn once_complete(o: &Once) -> (Bool, SyncError)
  if !o.running
    ret (false, SyncError::Invalid)
  .end
  set o.running = false
  set o.done = true
  ret (true, SyncError::Ok)
.end

fn once_reset(o: &Once) -> (Bool, SyncError)
  set o.running = false
  set o.done = false
  ret (true, SyncError::Ok)
.end

# OnceCell[T] (local)
# - Stores a value set once.
# - Uses `*null[T]()` as default placeholder for bootstrap.

type OnceCell[T] struct
  once: Once
  has: Bool
  val: T
.end

fn oncecell_new[T]() -> OnceCell[T]
  let c: OnceCell[T]
  set c.once = once_new()
  set c.has = false
  set c.val = *null[T]()
  ret c
.end

fn oncecell_set[T](c: &OnceCell[T], v: T) -> (Bool, SyncError)
  let ok: Bool
  let e: SyncError
  let run: Bool
  (ok, e, run) = once_begin(&c.once)
  if !ok
    ret (false, e)
  .end
  if !run
    ret (false, SyncError::Busy)
  .end

  set c.val = v
  set c.has = true
  (ok, e) = once_complete(&c.once)
  if !ok
    ret (false, e)
  .end
  ret (true, SyncError::Ok)
.end

fn oncecell_has[T](c: &OnceCell[T]) -> Bool
  ret c.has
.end

fn oncecell_get[T](c: &OnceCell[T]) -> (Bool, SyncError, Bool, T)
  if !c.has
    ret (true, SyncError::Ok, false, *null[T]())
  .end
  ret (true, SyncError::Ok, true, c.val)
.end

fn oncecell_ptr[T](c: &OnceCell[T]) -> (Bool, SyncError, Bool, Ptr[T])
  if !c.has
    ret (true, SyncError::Ok, false, null[T]())
  .end
  ret (true, SyncError::Ok, true, (Ptr[T])&c.val)
.end

# -----------------------------------------------------------------------------
# Semaphore (local)
# -----------------------------------------------------------------------------

type Semaphore struct
  count: I64
.end

fn sem_zero() -> Semaphore
  let s: Semaphore
  set s.count = 0
  ret s
.end

fn sem_new(init: I64) -> (Bool, SyncError, Semaphore)
  if init < 0
    ret (false, SyncError::Invalid, sem_zero())
  .end
  let s: Semaphore
  set s.count = init
  ret (true, SyncError::Ok, s)
.end

fn sem_count(s: &Semaphore) -> I64
  ret s.count
.end

fn sem_try_acquire(s: &Semaphore) -> (Bool, SyncError)
  if s.count <= 0
    ret (false, SyncError::WouldBlock)
  .end
  set s.count = s.count - 1
  ret (true, SyncError::Ok)
.end

fn sem_release(s: &Semaphore, n: I64) -> (Bool, SyncError)
  if n <= 0
    ret (false, SyncError::Invalid)
  .end
  set s.count = s.count + n
  ret (true, SyncError::Ok)
.end

# -----------------------------------------------------------------------------
# Event (local)
# -----------------------------------------------------------------------------

# Manual reset event.

type Event struct
  signaled: Bool
.end

fn event_new() -> Event
  let e: Event
  set e.signaled = false
  ret e
.end

fn event_set(e: &Event) -> (Bool, SyncError)
  set e.signaled = true
  ret (true, SyncError::Ok)
.end

fn event_reset(e: &Event) -> (Bool, SyncError)
  set e.signaled = false
  ret (true, SyncError::Ok)
.end

fn event_is_set(e: &Event) -> Bool
  ret e.signaled
.end

fn event_wait_spin(e: &Event, spins: U32) -> (Bool, SyncError)
  if e.signaled
    ret (true, SyncError::Ok)
  .end
  if spins == 0
    ret (false, SyncError::WouldBlock)
  .end

  let i: U32
  set i = 0
  while i < spins
    if e.signaled
      ret (true, SyncError::Ok)
    .end
    set i = i + 1
  .end

  ret (false, SyncError::Timeout)
.end

# Auto-reset event (local)

type AutoEvent struct
  signaled: Bool
.end

fn auto_event_new() -> AutoEvent
  let e: AutoEvent
  set e.signaled = false
  ret e
.end

fn auto_event_set(e: &AutoEvent) -> (Bool, SyncError)
  set e.signaled = true
  ret (true, SyncError::Ok)
.end

fn auto_event_wait(e: &AutoEvent) -> (Bool, SyncError)
  if !e.signaled
    ret (false, SyncError::WouldBlock)
  .end
  set e.signaled = false
  ret (true, SyncError::Ok)
.end

# -----------------------------------------------------------------------------
# CondVar (local)
# -----------------------------------------------------------------------------

# Condition variable modeled as a monotonic sequence.
# - notify_* increments seq.
# - wait observes seq, unlocks mutex, spins until seq changes, then re-locks.
# In single-thread mode, wait will generally return WouldBlock/Timeout.

type CondVar struct
  seq: U64
.end

fn condvar_new() -> CondVar
  let c: CondVar
  set c.seq = 0
  ret c
.end

fn condvar_seq(c: &CondVar) -> U64
  ret c.seq
.end

fn condvar_notify_one(c: &CondVar) -> (Bool, SyncError)
  set c.seq = c.seq + 1
  ret (true, SyncError::Ok)
.end

fn condvar_notify_all(c: &CondVar) -> (Bool, SyncError)
  set c.seq = c.seq + 1
  ret (true, SyncError::Ok)
.end

# wait returns (ok, err)
fn condvar_wait_spin(c: &CondVar, m: &Mutex, spins: U32) -> (Bool, SyncError)
  if !m.locked
    ret (false, SyncError::Invalid)
  .end

  let seen = c.seq

  # unlock then spin
  let ok: Bool
  let e: SyncError
  (ok, e) = mutex_unlock(m)
  if !ok
    ret (false, e)
  .end

  if spins == 0
    # re-lock best-effort
    (ok, e) = mutex_lock(m)
    if !ok
      ret (false, e)
    .end
    ret (false, SyncError::WouldBlock)
  .end

  let i: U32
  set i = 0
  while i < spins
    if c.seq != seen
      break
    .end
    set i = i + 1
  .end

  (ok, e) = mutex_lock(m)
  if !ok
    ret (false, e)
  .end

  if c.seq == seen
    ret (false, SyncError::Timeout)
  .end

  ret (true, SyncError::Ok)
.end

# -----------------------------------------------------------------------------
# Barrier / WaitGroup (local)
# -----------------------------------------------------------------------------

type Barrier struct
  parties: U32
  count: U32
  generation: U32
.end

fn barrier_zero() -> Barrier
  let b: Barrier
  set b.parties = 0
  set b.count = 0
  set b.generation = 0
  ret b
.end

fn barrier_new(parties: U32) -> (Bool, SyncError, Barrier)
  if parties == 0
    ret (false, SyncError::Invalid, barrier_zero())
  .end
  let b: Barrier
  set b.parties = parties
  set b.count = 0
  set b.generation = 0
  ret (true, SyncError::Ok, b)
.end

# Wait returns (ok, err, is_leader)
fn barrier_wait(b: &Barrier) -> (Bool, SyncError, Bool)
  if b.parties == 0
    ret (false, SyncError::Invalid, false)
  .end

  set b.count = b.count + 1

  if b.count < b.parties
    ret (false, SyncError::WouldBlock, false)
  .end

  set b.count = 0
  set b.generation = b.generation + 1
  ret (true, SyncError::Ok, true)
.end

# WaitGroup: counter that reaches 0.

type WaitGroup struct
  count: I64
.end

fn wg_new() -> WaitGroup
  let w: WaitGroup
  set w.count = 0
  ret w
.end

fn wg_add(w: &WaitGroup, delta: I64) -> (Bool, SyncError)
  if delta == 0
    ret (true, SyncError::Ok)
  .end
  if w.count + delta < 0
    ret (false, SyncError::Invalid)
  .end
  set w.count = w.count + delta
  ret (true, SyncError::Ok)
.end

fn wg_done(w: &WaitGroup) -> (Bool, SyncError)
  ret wg_add(w, -1)
.end

fn wg_count(w: &WaitGroup) -> I64
  ret w.count
.end

fn wg_wait_spin(w: &WaitGroup, spins: U32) -> (Bool, SyncError)
  if w.count == 0
    ret (true, SyncError::Ok)
  .end
  if spins == 0
    ret (false, SyncError::WouldBlock)
  .end

  let i: U32
  set i = 0
  while i < spins
    if w.count == 0
      ret (true, SyncError::Ok)
    .end
    set i = i + 1
  .end

  ret (false, SyncError::Timeout)
.end

fn wg_wait(w: &WaitGroup) -> (Bool, SyncError)
  ret wg_wait_spin(w, 0)
.end

# -----------------------------------------------------------------------------
# Simple MPSC queue (local) - generic
# -----------------------------------------------------------------------------

# NOTE: not thread-safe. Intended for single-thread message passing and to
# provide a stable API surface.

type Mpsc[T] struct
  q: Vec[T]
.end

fn mpsc_new[T]() -> Mpsc[T]
  let c: Mpsc[T]
  set c.q = vec_new[T]()
  ret c
.end

fn mpsc_drop[T](c: &Mpsc[T], deep: Bool)
  do vec_drop[T](&c.q, deep)
.end

fn mpsc_len[T](c: &Mpsc[T]) -> USize
  ret c.q.len
.end

fn mpsc_send[T](c: &Mpsc[T], v: T) -> (Bool, SyncError)
  let ok: Bool
  let e: ColError
  (ok, e) = vec_push[T](&c.q, 0, v)
  if !ok
    ret (false, SyncError::OutOfMemory)
  .end
  ret (true, SyncError::Ok)
.end

# recv returns (ok, err, has, value)
fn mpsc_recv[T](c: &Mpsc[T]) -> (Bool, SyncError, Bool, T)
  if c.q.len == 0
    ret (true, SyncError::Ok, false, *null[T]())
  .end

  # Pop front O(n): stable for bootstrap. A real backend would use a ring buffer.
  let v = *((Ptr[T])c.q.data + 0)

  let i: USize
  set i = 1
  while i < c.q.len
    let x = *((Ptr[T])c.q.data + i)
    set *((Ptr[T])c.q.data + (i - 1)) = x
    set i = i + 1
  .end

  do vec_pop[T](&c.q)
  ret (true, SyncError::Ok, true, v)
.end

# -----------------------------------------------------------------------------
# Smoke tests (scenarios)
# -----------------------------------------------------------------------------

scn test_sync_spinlock_basic
  let s = spinlock_new()
  let ok: Bool
  let e: SyncError

  (ok, e) = spinlock_try_lock(&s)
  do sync_expect(ok, "spin lock")

  (ok, e) = spinlock_try_lock(&s)
  do sync_expect(!ok && e == SyncError::Busy, "spin busy")

  (ok, e) = spinlock_unlock(&s)
  do sync_expect(ok, "spin unlock")
.end

scn test_sync_mutex_basic
  let m = mutex_new()
  let ok: Bool
  let e: SyncError

  (ok, e) = mutex_try_lock(&m)
  do sync_expect(ok, "mutex lock")
  do sync_expect(mutex_is_locked(&m), "mutex locked")

  (ok, e) = mutex_unlock(&m)
  do sync_expect(ok, "mutex unlock")
  do sync_expect(!mutex_is_locked(&m), "mutex unlocked")
.end

scn test_sync_mutexcell_basic
  let c = mutexcell_new[U64]((U64)1)
  let ok: Bool
  let e: SyncError
  let g: MutexGuard

  (ok, e, g) = mutexcell_try_lock[U64](&c)
  do sync_expect(ok, "mutexcell lock")

  let p = mutexcell_ptr[U64](&c)
  set *p = (U64)7

  (ok, e) = mutex_guard_unlock(&g)
  do sync_expect(ok, "mutexcell unlock")

  # re-lock and validate
  (ok, e, g) = mutexcell_try_lock[U64](&c)
  do sync_expect(ok, "mutexcell relock")
  let p2 = mutexcell_ptr[U64](&c)
  do sync_expect(*p2 == (U64)7, "mutexcell value")
  (ok, e) = mutex_guard_unlock(&g)
  do sync_expect(ok, "mutexcell final unlock")
.end

scn test_sync_rwlock_basic
  let r = rwlock_new()
  let ok: Bool
  let e: SyncError

  (ok, e) = rwlock_try_read(&r)
  do sync_expect(ok, "rw read")

  (ok, e) = rwlock_try_write(&r)
  do sync_expect(!ok && e == SyncError::Busy, "rw write busy")

  (ok, e) = rwlock_read_unlock(&r)
  do sync_expect(ok, "rw read unlock")

  (ok, e) = rwlock_try_write(&r)
  do sync_expect(ok, "rw write")

  (ok, e) = rwlock_write_unlock(&r)
  do sync_expect(ok, "rw write unlock")
.end

scn test_sync_once_and_oncecell
  let o = once_new()
  let ok: Bool
  let e: SyncError
  let run: Bool

  (ok, e, run) = once_begin(&o)
  do sync_expect(ok && run, "once begin run")
  (ok, e) = once_complete(&o)
  do sync_expect(ok, "once complete")

  (ok, e, run) = once_begin(&o)
  do sync_expect(ok && !run, "once begin skipped")

  let c = oncecell_new[U8]()
  (ok, e) = oncecell_set[U8](&c, (U8)'X')
  do sync_expect(ok, "oncecell set")

  let has: Bool
  let v: U8
  (ok, e, has, v) = oncecell_get[U8](&c)
  do sync_expect(ok && has && v == (U8)'X', "oncecell get")
.end

scn test_sync_sem_event_condvar_wg_mpsc
  let ok: Bool
  let e: SyncError

  # semaphore
  let sem: Semaphore
  (ok, e, sem) = sem_new(2)
  do sync_expect(ok, "sem new")
  (ok, e) = sem_try_acquire(&sem)
  do sync_expect(ok, "sem acq1")
  (ok, e) = sem_try_acquire(&sem)
  do sync_expect(ok, "sem acq2")
  (ok, e) = sem_try_acquire(&sem)
  do sync_expect(!ok && e == SyncError::WouldBlock, "sem wouldblock")
  (ok, e) = sem_release(&sem, 1)
  do sync_expect(ok, "sem rel")

  # event
  let ev = event_new()
  (ok, e) = event_wait_spin(&ev, 0)
  do sync_expect(!ok && e == SyncError::WouldBlock, "event wouldblock")
  (ok, e) = event_set(&ev)
  do sync_expect(ok && event_is_set(&ev), "event set")
  (ok, e) = event_wait_spin(&ev, 1)
  do sync_expect(ok, "event wait")

  # auto event
  let aev = auto_event_new()
  (ok, e) = auto_event_wait(&aev)
  do sync_expect(!ok && e == SyncError::WouldBlock, "auto event wouldblock")
  (ok, e) = auto_event_set(&aev)
  do sync_expect(ok, "auto event set")
  (ok, e) = auto_event_wait(&aev)
  do sync_expect(ok, "auto event wait")
  (ok, e) = auto_event_wait(&aev)
  do sync_expect(!ok && e == SyncError::WouldBlock, "auto event reset")

  # condvar (sequence only in local backend)
  let cv = condvar_new()
  let before = condvar_seq(&cv)
  (ok, e) = condvar_notify_one(&cv)
  do sync_expect(ok, "condvar notify")
  do sync_expect(condvar_seq(&cv) == before + 1, "condvar seq")

  # waitgroup
  let wg = wg_new()
  (ok, e) = wg_wait_spin(&wg, 0)
  do sync_expect(ok, "wg wait empty")
  (ok, e) = wg_add(&wg, 1)
  do sync_expect(ok, "wg add")
  (ok, e) = wg_wait_spin(&wg, 0)
  do sync_expect(!ok && e == SyncError::WouldBlock, "wg wouldblock")
  (ok, e) = wg_done(&wg)
  do sync_expect(ok, "wg done")
  (ok, e) = wg_wait_spin(&wg, 0)
  do sync_expect(ok, "wg wait")

  # mpsc
  let ch = mpsc_new[U8]()
  (ok, e) = mpsc_send[U8](&ch, (U8)'A')
  do sync_expect(ok, "mpsc send")
  let has2: Bool
  let vv: U8
  (ok, e, has2, vv) = mpsc_recv[U8](&ch)
  do sync_expect(ok && has2 && vv == (U8)'A', "mpsc recv")
  do mpsc_drop[U8](&ch, 0)
.end

# End of std.sync