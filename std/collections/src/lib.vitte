

# -----------------------------------------------------------------------------
# std/collections
# -----------------------------------------------------------------------------
# Facade + reference implementations for common collection types.
#
# Design goals:
# - predictable APIs (C-inspired)
# - explicit capacity management where relevant
# - zero hidden allocation policies: allocation is routed via an Allocator record
# - tests included as scenarios at the bottom of the file
#
# NOTE: This module is intentionally self-contained (single file) to simplify
# bootstrap. In a later split, each type can move to its own file and lib.vitte
# becomes a pure re-export facade.
# -----------------------------------------------------------------------------

module std.collections

# -----------------------------------------------------------------------------
# Minimal prelude (kept local to avoid dependency cycles during bootstrap)
# -----------------------------------------------------------------------------

type USize = usize
type ISize = isize

type U8   = u8
type U16  = u16
type U32  = u32
type U64  = u64

type I8   = i8
type I16  = i16
type I32  = i32
type I64  = i64

type F32  = f32
type F64  = f64

type Bool = bool

type Ptr[T] = ptr[T]

type Str = str

# Error model (small and stable): functions that can fail return (ok, err)
# where ok is Bool. The error is a small enum.

type ColError enum
  Ok
  OutOfMemory
  OutOfBounds
  Empty
  Invalid
.end

# -----------------------------------------------------------------------------
# Allocator
# -----------------------------------------------------------------------------
# The runtime is expected to provide these functions.
# If the runtime does not exist yet, stage0 can stub them.

fn rt_alloc(bytes: USize) -> Ptr[U8]
  # external
  ret (Ptr[U8])0
.end

fn rt_realloc(p: Ptr[U8], old_bytes: USize, new_bytes: USize) -> Ptr[U8]
  # external
  ret (Ptr[U8])0
.end

fn rt_free(p: Ptr[U8], bytes: USize)
  # external
  ret
.end

fn rt_memcpy(dst: Ptr[U8], src: Ptr[U8], bytes: USize)
  # external
  ret
.end

fn rt_memmove(dst: Ptr[U8], src: Ptr[U8], bytes: USize)
  # external
  ret
.end

fn rt_memset(dst: Ptr[U8], v: U8, bytes: USize)
  # external
  ret
.end

# Allocator record.
# If you later add arenas/pools, keep this stable and extend via optional fields.

type Allocator struct
  alloc: fn(USize)->Ptr[U8]
  realloc: fn(Ptr[U8], USize, USize)->Ptr[U8]
  free: fn(Ptr[U8], USize)->void
.end

fn allocator_default() -> Allocator
  let a: Allocator
  set a.alloc = rt_alloc
  set a.realloc = rt_realloc
  set a.free = rt_free
  ret a
.end

# Utility: align up
fn align_up(n: USize, a: USize) -> USize
  if a == 0
    ret n
  .end
  let r = n % a
  if r == 0
    ret n
  .end
  ret n + (a - r)
.end

# Utility: next power of two (>= 1)
fn next_pow2(x: USize) -> USize
  if x <= 1
    ret 1
  .end
  let v = x - 1
  set v = v | (v >> 1)
  set v = v | (v >> 2)
  set v = v | (v >> 4)
  set v = v | (v >> 8)
  set v = v | (v >> 16)
  # on 64-bit platforms, extend once more
  set v = v | (v >> 32)
  ret v + 1
.end

# -----------------------------------------------------------------------------
# Assertions (bootstrap-friendly)
# -----------------------------------------------------------------------------

fn panic(msg: Str)
  # external / trap
  ret
.end

fn assert(cond: Bool, msg: Str)
  if !cond
    do panic(msg)
  .end
.end

# -----------------------------------------------------------------------------
# Vec[T] (dynamic array)
# -----------------------------------------------------------------------------

type Vec[T] struct
  data: Ptr[T]
  len: USize
  cap: USize
  alloc: Allocator
.end

fn vec_new[T]() -> Vec[T]
  let v: Vec[T]
  set v.data = (Ptr[T])0
  set v.len = 0
  set v.cap = 0
  set v.alloc = allocator_default()
  ret v
.end

fn vec_with_allocator[T](a: Allocator) -> Vec[T]
  let v: Vec[T]
  set v.data = (Ptr[T])0
  set v.len = 0
  set v.cap = 0
  set v.alloc = a
  ret v
.end

fn vec_with_capacity[T](cap: USize) -> Vec[T]
  let v = vec_new[T]()
  let ok: Bool
  let err: ColError
  (ok, err) = vec_reserve[T](&v, cap)
  # ignore if OOM: keep empty vec; caller can check and handle by reserve themselves
  ret v
.end

fn vec_len[T](v: &Vec[T]) -> USize
  ret v.len
.end

fn vec_cap[T](v: &Vec[T]) -> USize
  ret v.cap
.end

fn vec_is_empty[T](v: &Vec[T]) -> Bool
  ret v.len == 0
.end

fn vec_clear[T](v: &Vec[T])
  set v.len = 0
.end

fn vec_drop[T](v: &Vec[T], elem_size: USize)
  # elem_size is explicit because sizeof(T) may not exist in stage0.
  if v.data == (Ptr[T])0
    ret
  .end
  let bytes = v.cap * elem_size
  do v.alloc.free((Ptr[U8])v.data, bytes)
  set v.data = (Ptr[T])0
  set v.len = 0
  set v.cap = 0
.end

fn vec_reserve[T](v: &Vec[T], additional: USize) -> (Bool, ColError)
  # Caller passes additional desired space.
  let needed = v.len + additional
  if needed <= v.cap
    ret (true, ColError::Ok)
  .end

  # Growth policy: next power of two, minimum 8.
  let new_cap = next_pow2(needed)
  if new_cap < 8
    set new_cap = 8
  .end

  # NOTE: stage0 may not support sizeof(T); require elem_size in a lower-level API.
  # Here we assume the runtime provides a layout map for T and the cast is valid.
  # If that is not true yet, use vec_reserve_bytes below.
  ret (false, ColError::Invalid)
.end

fn vec_reserve_bytes[T](v: &Vec[T], elem_size: USize, additional: USize) -> (Bool, ColError)
  let needed = v.len + additional
  if needed <= v.cap
    ret (true, ColError::Ok)
  .end

  let new_cap = next_pow2(needed)
  if new_cap < 8
    set new_cap = 8
  .end

  let old_bytes = v.cap * elem_size
  let new_bytes = new_cap * elem_size

  if v.data == (Ptr[T])0
    let p = v.alloc.alloc(new_bytes)
    if p == (Ptr[U8])0
      ret (false, ColError::OutOfMemory)
    .end
    set v.data = (Ptr[T])p
    set v.cap = new_cap
    ret (true, ColError::Ok)
  .end

  let p2 = v.alloc.realloc((Ptr[U8])v.data, old_bytes, new_bytes)
  if p2 == (Ptr[U8])0
    ret (false, ColError::OutOfMemory)
  .end

  set v.data = (Ptr[T])p2
  set v.cap = new_cap
  ret (true, ColError::Ok)
.end

fn vec_push[T](v: &Vec[T], elem_size: USize, x: T) -> (Bool, ColError)
  let ok: Bool
  let err: ColError
  (ok, err) = vec_reserve_bytes[T](v, elem_size, 1)
  if !ok
    ret (false, err)
  .end

  # store x at data[len]
  # NOTE: requires pointer arithmetic; assumed supported by backend.
  let idx = v.len
  let dst = (Ptr[U8])v.data + (idx * elem_size)
  do rt_memcpy(dst, (Ptr[U8])&x, elem_size)
  set v.len = v.len + 1
  ret (true, ColError::Ok)
.end

fn vec_pop[T](v: &Vec[T], out: &T) -> (Bool, ColError)
  if v.len == 0
    ret (false, ColError::Empty)
  .end
  set v.len = v.len - 1
  # out = data[len]
  # element size must be known to the caller; provide pop_bytes instead.
  ret (false, ColError::Invalid)
.end

fn vec_pop_bytes[T](v: &Vec[T], elem_size: USize, out: &T) -> (Bool, ColError)
  if v.len == 0
    ret (false, ColError::Empty)
  .end
  set v.len = v.len - 1
  let src = (Ptr[U8])v.data + (v.len * elem_size)
  do rt_memcpy((Ptr[U8])out, src, elem_size)
  ret (true, ColError::Ok)
.end

fn vec_get_ptr[T](v: &Vec[T], i: USize, elem_size: USize) -> (Bool, ColError, Ptr[T])
  if i >= v.len
    ret (false, ColError::OutOfBounds, (Ptr[T])0)
  .end
  let p = (Ptr[U8])v.data + (i * elem_size)
  ret (true, ColError::Ok, (Ptr[T])p)
.end

fn vec_swap_remove[T](v: &Vec[T], i: USize, elem_size: USize, out: &T) -> (Bool, ColError)
  if i >= v.len
    ret (false, ColError::OutOfBounds)
  .end

  # read removed
  let src = (Ptr[U8])v.data + (i * elem_size)
  do rt_memcpy((Ptr[U8])out, src, elem_size)

  let last = v.len - 1
  if i != last
    let src_last = (Ptr[U8])v.data + (last * elem_size)
    do rt_memcpy(src, src_last, elem_size)
  .end

  set v.len = v.len - 1
  ret (true, ColError::Ok)
.end

# Iterator (simple index-based)

type VecIter[T] struct
  v: &Vec[T]
  i: USize
  elem_size: USize
.end

fn vec_iter[T](v: &Vec[T], elem_size: USize) -> VecIter[T]
  let it: VecIter[T]
  set it.v = v
  set it.i = 0
  set it.elem_size = elem_size
  ret it
.end

fn vec_iter_next[T](it: &VecIter[T], out: &T) -> Bool
  if it.i >= it.v.len
    ret false
  .end
  let src = (Ptr[U8])it.v.data + (it.i * it.elem_size)
  do rt_memcpy((Ptr[U8])out, src, it.elem_size)
  set it.i = it.i + 1
  ret true
.end

# -----------------------------------------------------------------------------
# Deque[T] (ring buffer)
# -----------------------------------------------------------------------------

type Deque[T] struct
  data: Ptr[T]
  len: USize
  cap: USize
  head: USize
  alloc: Allocator
.end

fn deque_new[T]() -> Deque[T]
  let d: Deque[T]
  set d.data = (Ptr[T])0
  set d.len = 0
  set d.cap = 0
  set d.head = 0
  set d.alloc = allocator_default()
  ret d
.end

fn deque_index[T](d: &Deque[T], i: USize) -> USize
  # logical i -> physical index
  ret (d.head + i) % d.cap
.end

fn deque_reserve_bytes[T](d: &Deque[T], elem_size: USize, additional: USize) -> (Bool, ColError)
  let needed = d.len + additional
  if needed <= d.cap
    ret (true, ColError::Ok)
  .end

  let new_cap = next_pow2(needed)
  if new_cap < 8
    set new_cap = 8
  .end

  let new_bytes = new_cap * elem_size
  let p = d.alloc.alloc(new_bytes)
  if p == (Ptr[U8])0
    ret (false, ColError::OutOfMemory)
  .end

  # copy existing elements in order
  if d.len > 0
    let i: USize
    set i = 0
    loop
      if i >= d.len
        break
      .end
      let src_i = deque_index[T](d, i)
      let src = (Ptr[U8])d.data + (src_i * elem_size)
      let dst = (Ptr[U8])p + (i * elem_size)
      do rt_memcpy(dst, src, elem_size)
      set i = i + 1
    .end
  .end

  # free old
  if d.data != (Ptr[T])0
    do d.alloc.free((Ptr[U8])d.data, d.cap * elem_size)
  .end

  set d.data = (Ptr[T])p
  set d.cap = new_cap
  set d.head = 0
  ret (true, ColError::Ok)
.end

fn deque_push_back[T](d: &Deque[T], elem_size: USize, x: T) -> (Bool, ColError)
  let ok: Bool
  let err: ColError
  (ok, err) = deque_reserve_bytes[T](d, elem_size, 1)
  if !ok
    ret (false, err)
  .end

  let idx = deque_index[T](d, d.len)
  let dst = (Ptr[U8])d.data + (idx * elem_size)
  do rt_memcpy(dst, (Ptr[U8])&x, elem_size)
  set d.len = d.len + 1
  ret (true, ColError::Ok)
.end

fn deque_push_front[T](d: &Deque[T], elem_size: USize, x: T) -> (Bool, ColError)
  let ok: Bool
  let err: ColError
  (ok, err) = deque_reserve_bytes[T](d, elem_size, 1)
  if !ok
    ret (false, err)
  .end

  set d.head = (d.head + d.cap - 1) % d.cap
  let dst = (Ptr[U8])d.data + (d.head * elem_size)
  do rt_memcpy(dst, (Ptr[U8])&x, elem_size)
  set d.len = d.len + 1
  ret (true, ColError::Ok)
.end

fn deque_pop_front[T](d: &Deque[T], elem_size: USize, out: &T) -> (Bool, ColError)
  if d.len == 0
    ret (false, ColError::Empty)
  .end

  let src = (Ptr[U8])d.data + (d.head * elem_size)
  do rt_memcpy((Ptr[U8])out, src, elem_size)
  set d.head = (d.head + 1) % d.cap
  set d.len = d.len - 1
  ret (true, ColError::Ok)
.end

fn deque_pop_back[T](d: &Deque[T], elem_size: USize, out: &T) -> (Bool, ColError)
  if d.len == 0
    ret (false, ColError::Empty)
  .end

  let idx = deque_index[T](d, d.len - 1)
  let src = (Ptr[U8])d.data + (idx * elem_size)
  do rt_memcpy((Ptr[U8])out, src, elem_size)
  set d.len = d.len - 1
  ret (true, ColError::Ok)
.end

fn deque_len[T](d: &Deque[T]) -> USize
  ret d.len
.end

fn deque_is_empty[T](d: &Deque[T]) -> Bool
  ret d.len == 0
.end

fn deque_drop[T](d: &Deque[T], elem_size: USize)
  if d.data == (Ptr[T])0
    ret
  .end
  do d.alloc.free((Ptr[U8])d.data, d.cap * elem_size)
  set d.data = (Ptr[T])0
  set d.len = 0
  set d.cap = 0
  set d.head = 0
.end

# -----------------------------------------------------------------------------
# Stack[T] / Queue[T]
# -----------------------------------------------------------------------------

type Stack[T] struct
  v: Vec[T]
  elem_size: USize
.end

fn stack_new[T](elem_size: USize) -> Stack[T]
  let s: Stack[T]
  set s.v = vec_new[T]()
  set s.elem_size = elem_size
  ret s
.end

fn stack_push[T](s: &Stack[T], x: T) -> (Bool, ColError)
  ret vec_push[T](&s.v, s.elem_size, x)
.end

fn stack_pop[T](s: &Stack[T], out: &T) -> (Bool, ColError)
  ret vec_pop_bytes[T](&s.v, s.elem_size, out)
.end

fn stack_len[T](s: &Stack[T]) -> USize
  ret s.v.len
.end

fn stack_drop[T](s: &Stack[T])
  do vec_drop[T](&s.v, s.elem_size)
.end


type Queue[T] struct
  d: Deque[T]
  elem_size: USize
.end

fn queue_new[T](elem_size: USize) -> Queue[T]
  let q: Queue[T]
  set q.d = deque_new[T]()
  set q.elem_size = elem_size
  ret q
.end

fn queue_push[T](q: &Queue[T], x: T) -> (Bool, ColError)
  ret deque_push_back[T](&q.d, q.elem_size, x)
.end

fn queue_pop[T](q: &Queue[T], out: &T) -> (Bool, ColError)
  ret deque_pop_front[T](&q.d, q.elem_size, out)
.end

fn queue_len[T](q: &Queue[T]) -> USize
  ret q.d.len
.end

fn queue_drop[T](q: &Queue[T])
  do deque_drop[T](&q.d, q.elem_size)
.end

# -----------------------------------------------------------------------------
# Hashing helpers (bootstrap-grade)
# -----------------------------------------------------------------------------

# A hasher is a pure function returning a 64-bit hash.
# Equality is a pure predicate.

type HashFn[K] = fn(&K)->U64
type EqFn[K] = fn(&K, &K)->Bool

# FNV-1a for bytes (baseline)
fn hash_fnv1a(bytes: Ptr[U8], n: USize) -> U64
  let h: U64
  set h = 14695981039346656037
  let i: USize
  set i = 0
  loop
    if i >= n
      break
    .end
    let b = *(bytes + i)
    set h = h ^ (U64)b
    set h = h * 1099511628211
    set i = i + 1
  .end
  ret h
.end

# A default string hasher (Str assumed to have ptr+len ABI in runtime; stage0 may override)
# Here we provide a placeholder signature to keep the API stable.
fn hash_str(s: &Str) -> U64
  # external in real runtime; placeholder
  ret 0
.end

fn eq_str(a: &Str, b: &Str) -> Bool
  # external in real runtime; placeholder
  ret false
.end

# -----------------------------------------------------------------------------
# HashMap[K,V] (open addressing, linear probing)
# -----------------------------------------------------------------------------

# Slot states
const HM_EMPTY: U8 = 0
const HM_FILLED: U8 = 1
const HM_TOMBSTONE: U8 = 2

# Entry stores hash for faster probing; key/value bytes are stored inline.
# elem sizes are explicit (bootstrap-friendly).

type HashMap[K, V] struct
  keys: Ptr[U8]      # byte array for K
  vals: Ptr[U8]      # byte array for V
  hashes: Ptr[U64]
  states: Ptr[U8]
  len: USize
  cap: USize

  key_size: USize
  val_size: USize

  hash: HashFn[K]
  eq: EqFn[K]

  alloc: Allocator
.end

fn hashmap_new[K, V](key_size: USize, val_size: USize, hash: HashFn[K], eq: EqFn[K]) -> HashMap[K, V]
  let m: HashMap[K, V]
  set m.keys = (Ptr[U8])0
  set m.vals = (Ptr[U8])0
  set m.hashes = (Ptr[U64])0
  set m.states = (Ptr[U8])0
  set m.len = 0
  set m.cap = 0
  set m.key_size = key_size
  set m.val_size = val_size
  set m.hash = hash
  set m.eq = eq
  set m.alloc = allocator_default()
  ret m
.end

fn hashmap_load_factor_exceeded(m: &HashMap[_, _]) -> Bool
  # grow at 70% (cap==0 => false)
  if m.cap == 0
    ret false
  .end
  ret (m.len * 10) >= (m.cap * 7)
.end

fn hashmap_alloc_arrays[K, V](m: &HashMap[K, V], cap: USize) -> (Bool, ColError)
  let c = next_pow2(cap)
  if c < 8
    set c = 8
  .end

  let keys_b = c * m.key_size
  let vals_b = c * m.val_size
  let hashes_b = c * 8
  let states_b = c

  let pkeys = m.alloc.alloc(keys_b)
  if pkeys == (Ptr[U8])0
    ret (false, ColError::OutOfMemory)
  .end
  let pvals = m.alloc.alloc(vals_b)
  if pvals == (Ptr[U8])0
    do m.alloc.free(pkeys, keys_b)
    ret (false, ColError::OutOfMemory)
  .end
  let phashes = m.alloc.alloc(hashes_b)
  if phashes == (Ptr[U8])0
    do m.alloc.free(pkeys, keys_b)
    do m.alloc.free(pvals, vals_b)
    ret (false, ColError::OutOfMemory)
  .end
  let pstates = m.alloc.alloc(states_b)
  if pstates == (Ptr[U8])0
    do m.alloc.free(pkeys, keys_b)
    do m.alloc.free(pvals, vals_b)
    do m.alloc.free(phashes, hashes_b)
    ret (false, ColError::OutOfMemory)
  .end

  do rt_memset(pstates, HM_EMPTY, states_b)

  set m.keys = pkeys
  set m.vals = pvals
  set m.hashes = (Ptr[U64])phashes
  set m.states = pstates
  set m.cap = c
  ret (true, ColError::Ok)
.end

fn hashmap_free_arrays[K, V](m: &HashMap[K, V])
  if m.cap == 0
    ret
  .end
  do m.alloc.free(m.keys, m.cap * m.key_size)
  do m.alloc.free(m.vals, m.cap * m.val_size)
  do m.alloc.free((Ptr[U8])m.hashes, m.cap * 8)
  do m.alloc.free(m.states, m.cap)

  set m.keys = (Ptr[U8])0
  set m.vals = (Ptr[U8])0
  set m.hashes = (Ptr[U64])0
  set m.states = (Ptr[U8])0
  set m.cap = 0
  set m.len = 0
.end

fn hashmap_probe_start(h: U64, cap: USize) -> USize
  # cap is power of two
  ret (USize)(h & (U64)(cap - 1))
.end

fn hashmap_find_slot[K, V](m: &HashMap[K, V], key: &K, h: U64) -> (Bool, USize)
  # returns (found, idx)
  let cap = m.cap
  let i = hashmap_probe_start(h, cap)
  let first_tomb: ISize
  set first_tomb = -1

  let n: USize
  set n = 0
  loop
    if n >= cap
      break
    .end

    let st = *(m.states + i)
    if st == HM_EMPTY
      if first_tomb >= 0
        ret (false, (USize)first_tomb)
      .end
      ret (false, i)
    .end

    if st == HM_TOMBSTONE
      if first_tomb < 0
        set first_tomb = (ISize)i
      .end
    .end

    if st == HM_FILLED
      let hh = *(m.hashes + i)
      if hh == h
        # compare keys
        let kptr = m.keys + (i * m.key_size)
        if m.eq((K*)kptr, key)
          ret (true, i)
        .end
      .end
    .end

    set i = (i + 1) % cap
    set n = n + 1
  .end

  # full table (should not happen with growth policy)
  if first_tomb >= 0
    ret (false, (USize)first_tomb)
  .end
  ret (false, 0)
.end

fn hashmap_rehash[K, V](m: &HashMap[K, V], new_cap: USize) -> (Bool, ColError)
  # allocate new arrays
  let old_keys = m.keys
  let old_vals = m.vals
  let old_hashes = m.hashes
  let old_states = m.states
  let old_cap = m.cap

  set m.keys = (Ptr[U8])0
  set m.vals = (Ptr[U8])0
  set m.hashes = (Ptr[U64])0
  set m.states = (Ptr[U8])0
  set m.cap = 0

  let ok: Bool
  let err: ColError
  (ok, err) = hashmap_alloc_arrays[K, V](m, new_cap)
  if !ok
    # restore
    set m.keys = old_keys
    set m.vals = old_vals
    set m.hashes = old_hashes
    set m.states = old_states
    set m.cap = old_cap
    ret (false, err)
  .end

  let old_len = m.len
  set m.len = 0

  if old_cap > 0
    let i: USize
    set i = 0
    loop
      if i >= old_cap
        break
      .end
      if *(old_states + i) == HM_FILLED
        let h = *(old_hashes + i)
        let ksrc = old_keys + (i * m.key_size)
        let vsrc = old_vals + (i * m.val_size)

        # insert into new
        let found: Bool
        let idx: USize
        (found, idx) = hashmap_find_slot[K, V](m, (K*)ksrc, h)
        # must be false
        let kdst = m.keys + (idx * m.key_size)
        let vdst = m.vals + (idx * m.val_size)
        do rt_memcpy(kdst, ksrc, m.key_size)
        do rt_memcpy(vdst, vsrc, m.val_size)
        *(m.hashes + idx) = h
        *(m.states + idx) = HM_FILLED
        set m.len = m.len + 1
      .end
      set i = i + 1
    .end

    # free old arrays
    let keys_b = old_cap * m.key_size
    let vals_b = old_cap * m.val_size
    let hashes_b = old_cap * 8
    let states_b = old_cap
    do m.alloc.free(old_keys, keys_b)
    do m.alloc.free(old_vals, vals_b)
    do m.alloc.free((Ptr[U8])old_hashes, hashes_b)
    do m.alloc.free(old_states, states_b)
  .end

  # sanity
  do assert(m.len == old_len, "hashmap_rehash: len mismatch")
  ret (true, ColError::Ok)
.end

fn hashmap_ensure_cap[K, V](m: &HashMap[K, V], extra: USize) -> (Bool, ColError)
  if m.cap == 0
    ret hashmap_alloc_arrays[K, V](m, 8)
  .end

  if (m.len + extra) * 10 < m.cap * 7
    ret (true, ColError::Ok)
  .end

  ret hashmap_rehash[K, V](m, m.cap * 2)
.end

fn hashmap_put[K, V](m: &HashMap[K, V], key: K, val: V) -> (Bool, ColError)
  let ok: Bool
  let err: ColError
  (ok, err) = hashmap_ensure_cap[K, V](m, 1)
  if !ok
    ret (false, err)
  .end

  let h = m.hash(&key)
  let found: Bool
  let idx: USize
  (found, idx) = hashmap_find_slot[K, V](m, &key, h)

  let kdst = m.keys + (idx * m.key_size)
  let vdst = m.vals + (idx * m.val_size)

  if found
    # overwrite value
    do rt_memcpy(vdst, (Ptr[U8])&val, m.val_size)
    ret (true, ColError::Ok)
  .end

  do rt_memcpy(kdst, (Ptr[U8])&key, m.key_size)
  do rt_memcpy(vdst, (Ptr[U8])&val, m.val_size)
  *(m.hashes + idx) = h
  *(m.states + idx) = HM_FILLED
  set m.len = m.len + 1

  # grow if needed
  if hashmap_load_factor_exceeded(m)
    (ok, err) = hashmap_rehash[K, V](m, m.cap * 2)
    if !ok
      # keep the inserted element; table is still valid
      ret (false, err)
    .end
  .end

  ret (true, ColError::Ok)
.end

fn hashmap_get[K, V](m: &HashMap[K, V], key: &K, out: &V) -> Bool
  if m.cap == 0
    ret false
  .end

  let h = m.hash(key)
  let found: Bool
  let idx: USize
  (found, idx) = hashmap_find_slot[K, V](m, key, h)
  if !found
    ret false
  .end

  let src = m.vals + (idx * m.val_size)
  do rt_memcpy((Ptr[U8])out, src, m.val_size)
  ret true
.end

fn hashmap_has[K, V](m: &HashMap[K, V], key: &K) -> Bool
  if m.cap == 0
    ret false
  .end
  let h = m.hash(key)
  let found: Bool
  let idx: USize
  (found, idx) = hashmap_find_slot[K, V](m, key, h)
  ret found
.end

fn hashmap_remove[K, V](m: &HashMap[K, V], key: &K, out: &V) -> Bool
  if m.cap == 0
    ret false
  .end

  let h = m.hash(key)
  let found: Bool
  let idx: USize
  (found, idx) = hashmap_find_slot[K, V](m, key, h)
  if !found
    ret false
  .end

  let src = m.vals + (idx * m.val_size)
  do rt_memcpy((Ptr[U8])out, src, m.val_size)

  *(m.states + idx) = HM_TOMBSTONE
  set m.len = m.len - 1
  ret true
.end

fn hashmap_len[K, V](m: &HashMap[K, V]) -> USize
  ret m.len
.end

fn hashmap_is_empty[K, V](m: &HashMap[K, V]) -> Bool
  ret m.len == 0
.end

fn hashmap_drop[K, V](m: &HashMap[K, V])
  do hashmap_free_arrays[K, V](m)
.end

# -----------------------------------------------------------------------------
# HashSet[T] (thin wrapper)
# -----------------------------------------------------------------------------

type HashSet[T] struct
  map: HashMap[T, U8]
.end

fn hashset_new[T](elem_size: USize, hash: HashFn[T], eq: EqFn[T]) -> HashSet[T]
  let s: HashSet[T]
  set s.map = hashmap_new[T, U8](elem_size, 1, hash, eq)
  ret s
.end

fn hashset_add[T](s: &HashSet[T], x: T) -> (Bool, ColError)
  ret hashmap_put[T, U8](&s.map, x, (U8)1)
.end

fn hashset_has[T](s: &HashSet[T], x: &T) -> Bool
  ret hashmap_has[T, U8](&s.map, x)
.end

fn hashset_remove[T](s: &HashSet[T], x: &T) -> Bool
  let tmp: U8
  ret hashmap_remove[T, U8](&s.map, x, &tmp)
.end

fn hashset_len[T](s: &HashSet[T]) -> USize
  ret s.map.len
.end

fn hashset_drop[T](s: &HashSet[T])
  do hashmap_drop[T, U8](&s.map)
.end

# -----------------------------------------------------------------------------
# Small algorithms commonly used with collections
# -----------------------------------------------------------------------------

fn slice_reverse_bytes(p: Ptr[U8], n: USize)
  # reverse in-place by bytes (not by elements)
  if n <= 1
    ret
  .end

  let i: USize
  let j: USize
  set i = 0
  set j = n - 1
  loop
    if i >= j
      break
    .end
    let a = *(p + i)
    let b = *(p + j)
    *(p + i) = b
    *(p + j) = a
    set i = i + 1
    set j = j - 1
  .end
.end

# -----------------------------------------------------------------------------
# Tests (scenarios)
# -----------------------------------------------------------------------------

# These tests are written to be runnable in a minimal harness.
# A real std test harness can discover and run `scn` items.

scn test_vec_push_pop_i32
  let elem_size: USize
  set elem_size = 4

  let v = vec_new[I32]()

  let ok: Bool
  let err: ColError

  (ok, err) = vec_push[I32](&v, elem_size, 10)
  do assert(ok, "vec_push failed")

  (ok, err) = vec_push[I32](&v, elem_size, 20)
  do assert(ok, "vec_push failed")

  do assert(vec_len[I32](&v) == 2, "vec_len mismatch")

  let x: I32
  (ok, err) = vec_pop_bytes[I32](&v, elem_size, &x)
  do assert(ok, "vec_pop failed")
  do assert(x == 20, "vec_pop value mismatch")

  (ok, err) = vec_pop_bytes[I32](&v, elem_size, &x)
  do assert(ok, "vec_pop failed")
  do assert(x == 10, "vec_pop value mismatch")

  do assert(vec_is_empty[I32](&v), "vec should be empty")

  do vec_drop[I32](&v, elem_size)
.end

scn test_deque_fifo_i32
  let elem_size: USize
  set elem_size = 4

  let d = deque_new[I32]()

  let ok: Bool
  let err: ColError

  (ok, err) = deque_push_back[I32](&d, elem_size, 1)
  do assert(ok, "push_back")
  (ok, err) = deque_push_back[I32](&d, elem_size, 2)
  do assert(ok, "push_back")
  (ok, err) = deque_push_back[I32](&d, elem_size, 3)
  do assert(ok, "push_back")

  let x: I32
  (ok, err) = deque_pop_front[I32](&d, elem_size, &x)
  do assert(ok, "pop_front")
  do assert(x == 1, "deque order")

  (ok, err) = deque_pop_front[I32](&d, elem_size, &x)
  do assert(ok, "pop_front")
  do assert(x == 2, "deque order")

  (ok, err) = deque_pop_front[I32](&d, elem_size, &x)
  do assert(ok, "pop_front")
  do assert(x == 3, "deque order")

  do assert(deque_is_empty[I32](&d), "deque should be empty")
  do deque_drop[I32](&d, elem_size)
.end

# HashMap tests rely on a toy i32 hasher/eq
fn hash_i32(x: &I32) -> U64
  # simple reversible mix for tests
  let v: U64
  set v = (U64)(*x)
  set v = v ^ (v >> 33)
  set v = v * 0xff51afd7ed558ccd
  set v = v ^ (v >> 33)
  set v = v * 0xc4ceb9fe1a85ec53
  set v = v ^ (v >> 33)
  ret v
.end

fn eq_i32(a: &I32, b: &I32) -> Bool
  ret *a == *b
.end

scn test_hashmap_put_get_remove_i32
  let key_size: USize
  let val_size: USize
  set key_size = 4
  set val_size = 4

  let m = hashmap_new[I32, I32](key_size, val_size, hash_i32, eq_i32)

  let ok: Bool
  let err: ColError

  (ok, err) = hashmap_put[I32, I32](&m, 1, 11)
  do assert(ok, "put")
  (ok, err) = hashmap_put[I32, I32](&m, 2, 22)
  do assert(ok, "put")
  (ok, err) = hashmap_put[I32, I32](&m, 3, 33)
  do assert(ok, "put")

  do assert(hashmap_len[I32, I32](&m) == 3, "len")

  let out: I32
  do assert(hashmap_get[I32, I32](&m, &1, &out), "get")
  do assert(out == 11, "val")

  do assert(hashmap_get[I32, I32](&m, &2, &out), "get")
  do assert(out == 22, "val")

  do assert(hashmap_get[I32, I32](&m, &3, &out), "get")
  do assert(out == 33, "val")

  do assert(hashmap_remove[I32, I32](&m, &2, &out), "remove")
  do assert(out == 22, "remove val")
  do assert(!hashmap_has[I32, I32](&m, &2), "should be removed")
  do assert(hashmap_len[I32, I32](&m) == 2, "len after remove")

  do hashmap_drop[I32, I32](&m)
.end

scn test_hashset_i32
  let s = hashset_new[I32](4, hash_i32, eq_i32)

  let ok: Bool
  let err: ColError

  (ok, err) = hashset_add[I32](&s, 10)
  do assert(ok, "add")
  (ok, err) = hashset_add[I32](&s, 20)
  do assert(ok, "add")

  do assert(hashset_has[I32](&s, &10), "has")
  do assert(hashset_has[I32](&s, &20), "has")
  do assert(!hashset_has[I32](&s, &30), "has")

  do assert(hashset_remove[I32](&s, &10), "remove")
  do assert(!hashset_has[I32](&s, &10), "removed")
  do assert(hashset_len[I32](&s) == 1, "len")

  do hashset_drop[I32](&s)
.end

# End of std.collections
