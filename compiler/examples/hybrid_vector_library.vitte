// Example: Hybrid C/Assembly Vector Library
// Demonstrates best practices for combining C and assembly

// Vector operations with assembly acceleration
// x86-64 SIMD operations combined with C wrapper

// Vector type
struct Vector {
    len: usize,
    data: *mut f32,
}

// Create vector
fn vector_new(len: usize) -> Vector {
    let v: Vector
    v.len = len
    v.data = malloc(len * 4)  // 4 bytes per f32
    return v
}

// Element access (C)
fn vector_get(v: Vector, i: usize) -> f32 {
    if i >= v.len {
        return 0.0
    }
    return v.data[i]
}

// Element set (C)
fn vector_set(v: Vector, i: usize, value: f32) {
    if i < v.len {
        v.data[i] = value
    }
}

// Dot product with SIMD acceleration (assembly + C)
fn vector_dot(a: Vector, b: Vector) -> f32 {
    if a.len != b.len {
        return 0.0
    }
    
    let result: f32 = 0.0
    let len = a.len
    
    // Process 4 floats at a time with SIMD
    let aligned_len = (len >> 2) << 2  // Align to 4-element chunks
    
    // SIMD loop (assembly)
    var i = 0
    if aligned_len > 0 {
        asm volatile (
            "xorps %%xmm0, %%xmm0; "            // Zero accumulator
            "0: "
            "movups (%1, %2, 4), %%xmm1; "      // Load 4 floats from a[i:i+4]
            "movups (%3, %2, 4), %%xmm2; "      // Load 4 floats from b[i:i+4]
            "mulps %%xmm2, %%xmm1; "            // Multiply element-wise
            "addps %%xmm1, %%xmm0; "            // Add to accumulator
            "add $4, %2; "                       // i += 4
            "cmp %4, %2; jl 0b; "               // Continue if i < aligned_len
            "movss %%xmm0, %0; "                // Store scalar result
            : "=m"(result)
            : "r"(a.data), "r"(0), "r"(b.data), "r"(aligned_len)
            : "xmm0", "xmm1", "xmm2", "memory"
        )
    }
    
    // Handle remaining elements (C)
    for i = aligned_len; i < len; i = i + 1 {
        result = result + vector_get(a, i) * vector_get(b, i)
    }
    
    return result
}

// Vector scale: v[i] *= scalar
fn vector_scale(v: Vector, scalar: f32) {
    let len = v.len
    
    asm volatile (
        "broadcast %1, %%xmm0; "                // Broadcast scalar to 4 floats
        "0: "
        "movups (%2, %3, 4), %%xmm1; "         // Load 4 floats
        "mulps %%xmm0, %%xmm1; "               // Multiply by scalar
        "movups %%xmm1, (%2, %3, 4); "         // Store result
        "add $4, %3; "
        "cmp %4, %3; jl 0b; "
        : : "r"(scalar), "r"(v.data), "r"(0), "r"(len >> 2)
        : "xmm0", "xmm1", "memory"
    )
}

// Vector add: a[i] += b[i]
fn vector_add(a: Vector, b: Vector) {
    if a.len != b.len {
        return
    }
    
    let len = a.len
    
    // SIMD for bulk operation
    asm volatile (
        "0: "
        "movups (%1, %3, 4), %%xmm0; "         // Load 4 floats from a
        "addps (%2, %3, 4), %%xmm0; "          // Add 4 floats from b
        "movups %%xmm0, (%1, %3, 4); "         // Store result in a
        "add $4, %3; "
        "cmp %4, %3; jl 0b; "
        : : "r"(a.data), "r"(b.data), "r"(0), "r"(len >> 2)
        : "xmm0", "memory"
    )
}

// Norm calculation (L2 norm)
fn vector_norm(v: Vector) -> f32 {
    let dot_product = vector_dot(v, v)
    return sqrt(dot_product)
}

// Matrix multiplication with assembly optimization
struct Matrix {
    rows: usize,
    cols: usize,
    data: *mut f32,
}

// C = A * B (optimized)
fn matrix_multiply(a: Matrix, b: Matrix, c: Matrix) {
    if a.cols != b.rows || c.rows != a.rows || c.cols != b.cols {
        return
    }
    
    let m = a.rows      // Result rows
    let n = b.cols      // Result columns
    let k = a.cols      // Inner dimension
    
    // Loop over result matrix
    for var i = 0; i < m; i = i + 1 {
        for var j = 0; j < n; j = j + 1 {
            // Compute C[i,j] = dot(A[i,:], B[:,j])
            let sum: f32 = 0.0
            
            // Inner product loop - can be accelerated
            for var p = 0; p < k; p = p + 1 {
                let a_val = a.data[i * a.cols + p]
                let b_val = b.data[p * b.cols + j]
                sum = sum + a_val * b_val
            }
            
            c.data[i * c.cols + j] = sum
        }
    }
}

// Cache-aware transposition with assembly
fn matrix_transpose(src: Matrix, dst: Matrix) {
    let rows = src.rows
    let cols = src.cols
    
    if dst.rows != cols || dst.cols != rows {
        return
    }
    
    // For small matrices, use simple transpose
    if rows <= 64 && cols <= 64 {
        simple_transpose(src, dst)
        return
    }
    
    // For large matrices, use cache-optimized block transpose
    let block_size = 32  // 32x32 blocks for L1 cache
    
    var bi = 0
    while bi < rows {
        var bj = 0
        while bj < cols {
            // Process block
            let bi_end = if bi + block_size < rows { bi + block_size } else { rows }
            let bj_end = if bj + block_size < cols { bj + block_size } else { cols }
            
            for var i = bi; i < bi_end; i = i + 1 {
                for var j = bj; j < bj_end; j = j + 1 {
                    dst.data[j * dst.cols + i] = src.data[i * src.cols + j]
                }
            }
            
            bj = bj + block_size
        }
        bi = bi + block_size
    }
}

// Simple transpose helper
fn simple_transpose(src: Matrix, dst: Matrix) {
    for var i = 0; i < src.rows; i = i + 1 {
        for var j = 0; j < src.cols; j = j + 1 {
            dst.data[j * dst.cols + i] = src.data[i * src.cols + j]
        }
    }
}

// Benchmarking function
fn benchmark_operations() {
    let size = 1024
    let v1 = vector_new(size)
    let v2 = vector_new(size)
    
    // Initialize vectors
    for var i = 0; i < size; i = i + 1 {
        vector_set(v1, i, f32_of_i32(i))
        vector_set(v2, i, f32_of_i32(i + 1))
    }
    
    // Benchmark dot product
    let start = rdtsc()
    let result = vector_dot(v1, v2)
    let end = rdtsc()
    
    let cycles_per_call = (end - start) / 1000
    printf("Dot product: %f (cycles: %d)\n", result, cycles_per_call)
    
    // Benchmark vector scale
    start = rdtsc()
    for var i = 0; i < 1000; i = i + 1 {
        vector_scale(v1, 2.0)
    }
    end = rdtsc()
    
    cycles_per_call = (end - start) / 1000
    printf("Vector scale: %d cycles per call\n", cycles_per_call)
    
    // Cleanup
    free(v1.data)
    free(v2.data)
}

// Main demonstration
fn main() {
    println("=== Hybrid C/Assembly Vector Library ===")
    
    // Create vectors
    let v1 = vector_new(4)
    let v2 = vector_new(4)
    
    // Initialize
    vector_set(v1, 0, 1.0)
    vector_set(v1, 1, 2.0)
    vector_set(v1, 2, 3.0)
    vector_set(v1, 3, 4.0)
    
    vector_set(v2, 0, 2.0)
    vector_set(v2, 1, 3.0)
    vector_set(v2, 2, 4.0)
    vector_set(v2, 3, 5.0)
    
    // Compute dot product
    let dot = vector_dot(v1, v2)
    println("Dot product: %f", dot)
    // Expected: 1*2 + 2*3 + 3*4 + 4*5 = 2 + 6 + 12 + 20 = 40.0
    
    // Compute norm
    let norm = vector_norm(v1)
    println("Vector norm: %f", norm)
    // Expected: sqrt(1 + 4 + 9 + 16) = sqrt(30) â‰ˆ 5.477
    
    // Scale vector
    vector_scale(v1, 2.0)
    println("After scale by 2: [%f, %f, %f, %f]",
        vector_get(v1, 0),
        vector_get(v1, 1),
        vector_get(v1, 2),
        vector_get(v1, 3))
    
    // Cleanup
    free(v1.data)
    free(v2.data)
    
    // Benchmark
    benchmark_operations()
}

// Helper: Convert i32 to f32
fn f32_of_i32(x: i32) -> f32 {
    let result: f32
    
    asm "cvtsi2ss %1, %0"
        : "=x"(result)
        : "r"(x)
    
    return result
}

// Helper: Read timestamp counter
fn rdtsc() -> u64 {
    let result: u64
    
    asm "rdtsc; shl $32, %edx; or %edx, %eax"
        : "=a"(result)
    
    return result
}

// External C functions
extern fn malloc(size: usize) -> *mut void
extern fn free(ptr: *mut void)
extern fn sqrt(x: f32) -> f32
extern fn printf(fmt: *const u8, ...) -> i32
extern fn println(fmt: *const u8, ...)
