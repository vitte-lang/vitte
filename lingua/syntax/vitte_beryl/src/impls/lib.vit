// Lexer and tokenization implementations

impl Token {
    pub fn new(token_type: TokenType, value: string, line: u32, column: u32) -> Self {
        Token {
            token_type,
            value,
            line,
            column,
        }
    }

    pub fn get_value(&self) -> string {
        self.value.clone()
    }

    pub fn get_line(&self) -> u32 {
        self.line
    }
}

impl Lexer {
    pub fn new(input: string) -> Self {
        Lexer {
            input,
            position: 0,
            line: 1,
            column: 1,
        }
    }

    pub fn tokenize(&mut self) -> Vec<Token> {
        let mut tokens = Vec::new();
        while self.position < self.input.len() as u32 {
            let token = self.next_token();
            tokens.push(token);
        }
        tokens.push(Token::new(TokenType::EOF, "".to_string(), self.line, self.column));
        tokens
    }

    pub fn next_token(&mut self) -> Token {
        if self.position >= self.input.len() as u32 {
            return Token::new(TokenType::EOF, "".to_string(), self.line, self.column);
        }
        
        let current_char = self.input.chars().nth(self.position as usize).unwrap_or(' ');
        
        if current_char.is_whitespace() {
            self.position += 1;
            if current_char == '\n' {
                self.line += 1;
                self.column = 1;
            } else {
                self.column += 1;
            }
            Token::new(TokenType::Whitespace, current_char.to_string(), self.line, self.column)
        } else if current_char.is_alphabetic() {
            let start = self.position;
            while self.position < self.input.len() as u32 {
                let ch = self.input.chars().nth(self.position as usize).unwrap_or(' ');
                if ch.is_alphanumeric() || ch == '_' {
                    self.position += 1;
                    self.column += 1;
                } else {
                    break;
                }
            }
            let value = self.input[start as usize..self.position as usize].to_string();
            Token::new(TokenType::Identifier, value, self.line, self.column)
        } else {
            self.position += 1;
            self.column += 1;
            Token::new(TokenType::Operator, current_char.to_string(), self.line, self.column)
        }
    }
}

impl Bytecode {
    pub fn new() -> Self {
        Bytecode {
            instructions: Vec::new(),
        }
    }

    pub fn emit(&mut self, op: BytecodeOp) {
        self.instructions.push(op);
    }

    pub fn len(&self) -> u64 {
        self.instructions.len() as u64
    }
}

impl TokenBuffer {
    pub fn new() -> Self {
        TokenBuffer {
            tokens: Vec::new(),
            position: 0,
        }
    }

    pub fn add_token(&mut self, token: Token) {
        self.tokens.push(token);
    }

    pub fn next(&mut self) -> Option<Token> {
        if (self.position as usize) < self.tokens.len() {
            let token = self.tokens[self.position as usize].clone();
            self.position += 1;
            Some(token)
        } else {
            None
        }
    }

    pub fn peek(&self) -> Option<Token> {
        if (self.position as usize) < self.tokens.len() {
            Some(self.tokens[self.position as usize].clone())
        } else {
            None
        }
    }
}
